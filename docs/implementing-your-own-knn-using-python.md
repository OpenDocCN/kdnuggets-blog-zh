# å®ç°ä½ è‡ªå·±çš„ k-æœ€è¿‘é‚»ç®—æ³•ä½¿ç”¨ Python

> åŸæ–‡ï¼š[https://www.kdnuggets.com/2016/01/implementing-your-own-knn-using-python.html](https://www.kdnuggets.com/2016/01/implementing-your-own-knn-using-python.html)

**ä½œè€…ï¼šNatasha Latysheva**ã€‚

*ç¼–è¾‘æ³¨*ï¼šNatasha æ´»è·ƒäº [å‰‘æ¡¥ç¼–ç¨‹å­¦é™¢](https://cambridgecoding.com/)ï¼Œè¯¥å­¦é™¢å°†äº 2016 å¹´ 2 æœˆ 20-21 æ—¥ä¸¾åŠ [Python æ•°æ®ç§‘å­¦è®­ç»ƒè¥](https://cambridgecoding.com/datascience-bootcamp)ï¼Œåœ¨è¿™é‡Œä½ å¯ä»¥å­¦ä¹ é’ˆå¯¹ç°å®ä¸–ç•Œé—®é¢˜çš„æœ€å…ˆè¿›æœºå™¨å­¦ä¹ æŠ€æœ¯ã€‚

åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œä½ å¯èƒ½ç»å¸¸å¸Œæœ›æ„å»ºåˆ†ç±»å™¨ï¼Œå°†äº‹ç‰©åˆ†ç±»åˆ°æŸäº›ç±»åˆ«ä¸­ï¼Œè¿™äº›ç±»åˆ«æ˜¯åŸºäºä¸€ç»„ç›¸å…³å€¼ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥æ ¹æ®æ¥è‡ªå…ˆå‰æ‚£è€…çš„æ•°æ®ä¸ºæ‚£è€…æä¾›è¯Šæ–­ã€‚åˆ†ç±»å¯èƒ½æ¶‰åŠåœ¨ç±»åˆ«ä¹‹é—´æ„é€ é«˜åº¦éçº¿æ€§çš„è¾¹ç•Œï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºçš„çº¢è‰²ã€ç»¿è‰²å’Œè“è‰²ç±»åˆ« [ä¸‹é¢](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)ï¼š

![kNN è¾¹ç•Œ](../Images/4322b5f9ae66be35375b65bec3b6c05f.png)

è®¸å¤šç®—æ³•å·²ç»è¢«å¼€å‘ç”¨äºè‡ªåŠ¨åˆ†ç±»ï¼Œå¸¸è§çš„ç®—æ³•åŒ…æ‹¬éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºã€æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨å’Œå¤šç§ç±»å‹çš„ç¥ç»ç½‘ç»œã€‚ä¸ºäº†äº†è§£åˆ†ç±»çš„å·¥ä½œåŸç†ï¼Œæˆ‘ä»¬ä»¥ä¸€ä¸ªç®€å•çš„åˆ†ç±»ç®—æ³•â€”â€”k-æœ€è¿‘é‚»ï¼ˆkNNï¼‰ä¸ºä¾‹ï¼Œå¹¶åœ¨ Python 2 ä¸­ä»å¤´å¼€å§‹æ„å»ºå®ƒã€‚å¦‚æœä½ åˆšåˆšå¼€å§‹å­¦ä¹  Pythonï¼Œå¯ä»¥ä½¿ç”¨ä¸»è¦çš„ [å‘½ä»¤å¼ç¼–ç¨‹é£æ ¼](http://latentflip.com/imperative-vs-declarative/)ï¼Œè€Œä¸æ˜¯ä½¿ç”¨ [lambda å‡½æ•°](http://www.secnetix.de/olli/Python/lambda_functions.hawk) å’Œ [åˆ—è¡¨æ¨å¯¼å¼](http://www.secnetix.de/olli/Python/list_comprehensions.hawk) çš„å£°æ˜å¼/å‡½æ•°å¼é£æ ¼ï¼Œä»¥ä¿æŒç®€å•ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä»‹ç»åä¸€ç§æ–¹æ³•ã€‚kNN é€šè¿‡å°†æ–°çš„å®ä¾‹ä¸æœ€ç›¸ä¼¼çš„æ¡ˆä¾‹åˆ†ç»„æ¥è¿›è¡Œåˆ†ç±»ã€‚åœ¨è¿™é‡Œï¼Œä½ å°†ä½¿ç”¨ kNN å¤„ç†æµè¡Œçš„ï¼ˆå°½ç®¡æ˜¯ç†æƒ³åŒ–çš„ï¼‰é¸¢å°¾èŠ±æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…æ‹¬ä¸‰ç§é¸¢å°¾èŠ±çš„èŠ±å‰æµ‹é‡æ•°æ®ã€‚æˆ‘ä»¬çš„ä»»åŠ¡æ˜¯æ ¹æ®èŠ±å‰æµ‹é‡æ•°æ®é¢„æµ‹èŠ±å‰çš„ç‰©ç§æ ‡ç­¾ã€‚ç”±äºä½ å°†åŸºäºä¸€ç»„å·²çŸ¥çš„æ­£ç¡®åˆ†ç±»æ¥æ„å»ºé¢„æµ‹å™¨ï¼Œå› æ­¤ kNN æ˜¯ä¸€ç§ç›‘ç£å¼æœºå™¨å­¦ä¹ ï¼ˆè™½ç„¶æœ‰äº›ä»¤äººå›°æƒ‘çš„æ˜¯ï¼Œåœ¨ kNN ä¸­æ²¡æœ‰æ˜¾å¼çš„è®­ç»ƒé˜¶æ®µï¼›è¯·å‚è§ [æ‡’æƒ°å­¦ä¹ ](https://en.wikipedia.org/wiki/Lazy_learning)ï¼‰ã€‚kNN ä»»åŠ¡å¯ä»¥åˆ†è§£ä¸ºç¼–å†™ 3 ä¸ªä¸»è¦åŠŸèƒ½ï¼š

1\. è®¡ç®—ä»»ä½•ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»

2\. åŸºäºè¿™äº›æˆå¯¹è·ç¦»æ‰¾åˆ°æœ€è¿‘é‚»

3\. åŸºäºæœ€è¿‘é‚»åˆ—è¡¨å¯¹ç±»åˆ«æ ‡ç­¾è¿›è¡Œå¤šæ•°æŠ•ç¥¨

ä»¥ä¸‹å›¾ä¸­çš„æ­¥éª¤æä¾›äº†ä½ åœ¨ä»£ç ä¸­éœ€è¦å®Œæˆä»»åŠ¡çš„é«˜å±‚æ¬¡æ¦‚è¿°ã€‚

[![kNN ç®—æ³•](../Images/39dbb98036b866c0b324bcb95cf9762c.png)](https://cambridgecoding.files.wordpress.com/2016/01/knn2.jpg)

**ç®—æ³•**

ç®€è€Œè¨€ä¹‹ï¼Œä½ å°†æ„å»ºä¸€ä¸ªè„šæœ¬ï¼Œå¯¹äºæ¯ä¸ªéœ€è¦åˆ†ç±»çš„è¾“å…¥ï¼Œæœç´¢æ•´ä¸ªè®­ç»ƒé›†ä¸­çš„ k ä¸ªæœ€ç›¸ä¼¼çš„å®ä¾‹ã€‚ç„¶åï¼Œé€šè¿‡å¤šæ•°æŠ•ç¥¨æ€»ç»“æœ€ç›¸ä¼¼å®ä¾‹çš„ç±»åˆ«æ ‡ç­¾ï¼Œå¹¶å°†å…¶ä½œä¸ºæµ‹è¯•æ¡ˆä¾‹çš„é¢„æµ‹ç»“æœè¿”å›ã€‚

å®Œæ•´çš„ä»£ç åœ¨æ–‡ç« çš„æœ€åã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬åˆ†åˆ«æŸ¥çœ‹ä¸åŒéƒ¨åˆ†å¹¶è§£é‡Šå®ƒä»¬çš„åŠŸèƒ½ã€‚

åŠ è½½æ•°æ®å¹¶æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ä¸ºäº†å¿«é€Ÿä¸Šæ‰‹ï¼Œä½ å°†ä½¿ç”¨ä¸€äº›è¾…åŠ©å‡½æ•°ï¼šè™½ç„¶æˆ‘ä»¬å¯ä»¥è‡ªå·±[ä¸‹è½½é¸¢å°¾èŠ±æ•°æ®](https://archive.ics.uci.edu/ml/datasets/Iris)å¹¶ä½¿ç”¨[csv.reader](https://docs.python.org/2/library/csv.html)åŠ è½½å®ƒï¼Œä½ ä¹Ÿå¯ä»¥ç›´æ¥ä» scikit-learn å¿«é€Ÿè·å–é¸¢å°¾èŠ±æ•°æ®ã€‚æ­¤å¤–ï¼Œä½ å¯ä»¥ä½¿ç”¨ train_test_split å‡½æ•°è¿›è¡Œ 60/40 çš„è®­ç»ƒ/æµ‹è¯•æ‹†åˆ†ï¼Œä½†ä½ ä¹Ÿå¯ä»¥è‡ªå·±éšæœºåˆ†é…è¡Œï¼ˆè¯·å‚è§æ­¤ç±»å‹çš„å®ç°ï¼‰ã€‚åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œè®­ç»ƒ/æµ‹è¯•æ‹†åˆ†ç”¨äºå‡å°‘è¿‡æ‹Ÿåˆâ€”â€”åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹å¾€å¾€ä¼šå¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆæ•°æ®çš„å™ªå£°å’Œç‰¹æ€§ï¼Œè€Œä¸æ˜¯å®é™…çš„åº•å±‚è¶‹åŠ¿ã€‚ä½ åªåœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œä»»ä½•ç±»å‹çš„æ¨¡å‹è°ƒæ•´ï¼ˆä¾‹å¦‚ï¼Œé€‰æ‹©é‚»å±…çš„æ•°é‡ kï¼‰â€”â€”æµ‹è¯•é›†ä½œä¸ºä¸€ä¸ªç‹¬ç«‹çš„ã€æœªè§¦åŠçš„æ•°æ®é›†ï¼Œç”¨äºæµ‹è¯•æœ€ç»ˆæ¨¡å‹çš„æ€§èƒ½ã€‚

```py
from sklearn.datasets import load_iris
from sklearn import cross_validation
import numpy as np

# load dataset and partition in training and testing sets
iris = load_iris()
X_train, X_test, y_train, y_test = cross_validation.train_test_split(iris.data, iris.target, test_size=0.4, random_state=1)

# reformat train/test datasets for convenience
train = np.array(zip(X_train,y_train))
test = np.array(zip(X_test, y_test))

```

è¿™æ˜¯é¸¢å°¾èŠ±æ•°æ®é›†ã€æ•°æ®æ‹†åˆ†ä»¥åŠç´¢å¼•çš„ç®€è¦æŒ‡å—ã€‚

[![æ‹†åˆ†é¸¢å°¾èŠ±æ•°æ®é›†](../Images/8099def34ac1f68142c2841020df09ca.png)](https://cambridgecoding.files.wordpress.com/2016/01/knn3.jpg)

### æ›´å¤šç›¸å…³å†…å®¹

+   [ä»ç†è®ºåˆ°å®è·µï¼šæ„å»ºä¸€ä¸ª k-æœ€è¿‘é‚»åˆ†ç±»å™¨](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)

+   [åˆ†ç±»çš„æœ€è¿‘é‚»](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)

+   [Scikit-learn ä¸­çš„ k-æœ€è¿‘é‚»](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)

+   [LangChain 101ï¼šæ„å»ºä½ è‡ªå·±çš„ GPT é©±åŠ¨åº”ç”¨](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)

+   [ä½¿ç”¨ LlamaIndex æ„å»ºä½ è‡ªå·±çš„ PandasAI](https://www.kdnuggets.com/build-your-own-pandasai-with-llamaindex)

+   [ä½¿ç”¨ ChatGPT çš„ GPTs åˆ›å»ºä½ è‡ªå·±çš„ GPT](https://www.kdnuggets.com/make-your-own-gpts-with-chatgpts-gpts)
€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œå¯ä»¥é€šè¿‡æŸ¥çœ‹å“ªä¸ªå€¼äº§ç”Ÿæœ€å‡†ç¡®çš„é¢„æµ‹æ¥ä¼˜åŒ–kï¼ˆå‚è§ [äº¤å‰éªŒè¯](http://scikit-learn.org/stable/modules/cross_validation.html)ï¼‰ã€‚

å¯¹kNNçš„ä¸€ä¸ªå¾ˆå¥½çš„æ¦‚è¿°å¯ä»¥åœ¨ [è¿™é‡Œ](https://saravananthirumuruganathan.wordpress.com/2010/05/17/a-detailed-introduction-to-k-nearest-neighbor-knn-algorithm/) é˜…è¯»ã€‚ä¸€ä¸ªæ›´æ·±å…¥çš„å®ç°ï¼ŒåŒ…æ‹¬åŠ æƒå’Œæœç´¢æ ‘ï¼Œè§ [è¿™é‡Œ](http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_ml/py_knn/py_knn_understanding/py_knn_understanding.html)ã€‚

**å®Œæ•´è„šæœ¬**

å®Œæ•´çš„è„šæœ¬å¦‚ä¸‹ï¼š

```py
from sklearn.datasets import load_iris
from sklearn import cross_validation
from sklearn.metrics import classification_report, accuracy_score
from operator import itemgetter
import numpy as np
import math
from collections import Counter

# 1) given two data points, calculate the euclidean distance between them
def get_distance(data1, data2):
    points = zip(data1, data2)
    diffs_squared_distance = [pow(a - b, 2) for (a, b) in points]
    return math.sqrt(sum(diffs_squared_distance))

# 2) given a training set and a test instance, use getDistance to calculate all pairwise distances
def get_neighbours(training_set, test_instance, k):
    distances = [_get_tuple_distance(training_instance, test_instance) for training_instance in training_set]
    # index 1 is the calculated distance between training_instance and test_instance
    sorted_distances = sorted(distances, key=itemgetter(1))
    # extract only training instances
    sorted_training_instances = [tuple[0] for tuple in sorted_distances]
    # select first k elements
    return sorted_training_instances[:k]

def _get_tuple_distance(training_instance, test_instance):
    return (training_instance, get_distance(test_instance, training_instance[0]))

# 3) given an array of nearest neighbours for a test case, tally up their classes to vote on test case class
def get_majority_vote(neighbours):
    # index 1 is the class
    classes = [neighbour[1] for neighbour in neighbours]
    count = Counter(classes)
    return count.most_common()[0][0] 

# setting up main executable method
def main():

    # load the data and create the training and test sets
    # random_state = 1 is just a seed to permit reproducibility of the train/test split
    iris = load_iris()
    X_train, X_test, y_train, y_test = cross_validation.train_test_split(iris.data, iris.target, test_size=0.4, random_state=1)

    # reformat train/test datasets for convenience
    train = np.array(zip(X_train,y_train))
    test = np.array(zip(X_test, y_test))

    # generate predictions
    predictions = []

    # let's arbitrarily set k equal to 5, meaning that to predict the class of new instances,
    k = 5

    # for each instance in the test set, get nearest neighbours and majority vote on predicted class
    for x in range(len(X_test)):

            print 'Classifying test instance number ' + str(x) + ":",
            neighbours = get_neighbours(training_set=train, test_instance=test[x][0], k=5)
            majority_vote = get_majority_vote(neighbours)
            predictions.append(majority_vote)
            print 'Predicted label=' + str(majority_vote) + ', Actual label=' + str(test[x][1])

    # summarize performance of the classification
    print '\nThe overall accuracy of the model is: ' + str(accuracy_score(y_test, predictions)) + "\n"
    report = classification_report(y_test, predictions, target_names = iris.target_names)
    print 'A detailed classification report: \n\n' + report

if __name__ == "__main__":
    main()

```

**æƒ³äº†è§£æ›´å¤šï¼ŸæŸ¥çœ‹æˆ‘ä»¬çš„ä¸¤å¤©æ•°æ®ç§‘å­¦è®­ç»ƒè¥**ï¼š

[https://cambridgecoding.com/datascience-bootcamp](https://cambridgecoding.com/datascience-bootcamp)

**ç®€ä»‹ï¼š[Natasha Latysheva](http://blog.cambridgecoding.com/author/natlat/)** æ˜¯MRCåˆ†å­ç”Ÿç‰©å­¦å®éªŒå®¤çš„è®¡ç®—ç”Ÿç‰©å­¦åšå£«ç”Ÿã€‚å¥¹çš„ç ”ç©¶é›†ä¸­äºç™Œç—‡åŸºå› ç»„å­¦ã€ç»Ÿè®¡ç½‘ç»œåˆ†æå’Œè›‹ç™½è´¨ç»“æ„ã€‚æ›´å¹¿æ³›åœ°è¯´ï¼Œå¥¹çš„ç ”ç©¶å…´è¶£åŒ…æ‹¬æ•°æ®å¯†é›†å‹åˆ†å­ç”Ÿç‰©å­¦ã€æœºå™¨å­¦ä¹ ï¼ˆç‰¹åˆ«æ˜¯æ·±åº¦å­¦ä¹ ï¼‰å’Œæ•°æ®ç§‘å­¦ã€‚

[åŸæ–‡](http://blog.cambridgecoding.com/2016/01/16/machine-learning-under-the-hood-writing-your-own-k-nearest-neighbour-algorithm/)ã€‚ç»å…è®¸è½¬è½½ã€‚

**ç›¸å…³ï¼š**

+   [Scikit-learn å’Œ Python å †æ ˆæ•™ç¨‹ï¼šç®€ä»‹ï¼Œåˆ†ç±»å™¨å®ç°](/2016/01/scikit-learn-tutorials-introduction-classifiers.html)

+   [7 Steps to Mastering Machine Learning With Python](/2015/11/seven-steps-machine-learning-python.html)

+   [7 Steps to Understanding Deep Learning](/2016/01/seven-steps-deep-learning.html)

* * *

## æˆ‘ä»¬çš„ä¸‰å¤§è¯¾ç¨‹æ¨è

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google ç½‘ç»œå®‰å…¨è¯ä¹¦](https://www.kdnuggets.com/google-cybersecurity) - å¿«é€Ÿå…¥é—¨ç½‘ç»œå®‰å…¨èŒä¸šã€‚

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google æ•°æ®åˆ†æä¸“ä¸šè¯ä¹¦](https://www.kdnuggets.com/google-data-analytics) - æå‡ä½ çš„æ•°æ®åˆ†ææŠ€èƒ½

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT æ”¯æŒä¸“ä¸šè¯ä¹¦](https://www.kdnuggets.com/google-itsupport) - æ”¯æŒä½ æ‰€åœ¨ç»„ç»‡çš„ IT

* * *

### æ›´å¤šç›¸å…³è¯é¢˜

+   [ä»ç†è®ºåˆ°å®è·µï¼šæ„å»º k-æœ€è¿‘é‚»åˆ†ç±»å™¨](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)

+   [ç”¨äºåˆ†ç±»çš„æœ€è¿‘é‚»](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)

+   [Scikit-learn ä¸­çš„ K æœ€è¿‘é‚»](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)

+   [LangChain 101ï¼šæ„å»ºä½ è‡ªå·±çš„ GPT é©±åŠ¨åº”ç”¨](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)

+   [ä½¿ç”¨ LlamaIndex æ„å»ºä½ è‡ªå·±çš„ PandasAI](https://www.kdnuggets.com/build-your-own-pandasai-with-llamaindex)

+   [ä½¿ç”¨ ChatGPT çš„ GPTs åˆ›å»ºä½ è‡ªå·±çš„ GPT](https://www.kdnuggets.com/make-your-own-gpts-with-chatgpts-gpts)
